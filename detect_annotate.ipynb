{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_PATH = r\"videos\\vehicle-counting.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.87  Python-3.11.9 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 4GB Laptop GPU, 4096MiB)\n",
      "Setup complete  (16 CPUs, 15.7 GB RAM, 56.3/62.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "\n",
    "# Get the video's frame width and height\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 116.3ms\n",
      "Speed: 5.0ms preprocess, 116.3ms inference, 80.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "model = YOLO(r\"models\\yolov8x-worldv2.pt\")\n",
    "image = cv2.imread(r\"images\\first_frame-vehicle-counting.png\")\n",
    "results = model(image)[0]\n",
    "\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "labels = [\n",
    "    f\"{class_name} {confidence:.2f}\"\n",
    "    for class_name, confidence\n",
    "    in zip(detections['class_name'], detections.confidence)\n",
    "]\n",
    "\n",
    "annotated_image = box_annotator.annotate(\n",
    "    scene=image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(\n",
    "    scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "\n",
    "\n",
    "# Create a named window with the ability to resize\n",
    "cv2.namedWindow('Annotated Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "\n",
    "# Calculate aspect ratio\n",
    "aspect_ratio = width / height\n",
    "\n",
    "# Set the window size\n",
    "cv2.resizeWindow(\"Annotated Image\", int(400 * aspect_ratio), 400)\n",
    "\n",
    "# Display the annotated image\n",
    "cv2.imshow('Annotated Image', annotated_image)\n",
    "\n",
    "# Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".major_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
