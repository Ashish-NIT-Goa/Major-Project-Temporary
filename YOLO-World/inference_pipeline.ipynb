{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/10/24 16:07:45] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> is out of date! Please upgrade to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py:41</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of inference for the latest features and bug fixes by    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/10/24 16:07:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Your inference package version \u001b[1;36m0.17\u001b[0m.\u001b[1;36m1\u001b[0m is out of date! Please upgrade to \u001b[2m__init__.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m41\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         version \u001b[1;36m0.18\u001b[0m.\u001b[1;36m1\u001b[0m of inference for the latest features and bug fixes by    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         running `pip install --upgrade inference`.                              \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SupervisionWarnings: BoundingBoxAnnotator is deprecated: `BoundingBoxAnnotator` is deprecated and has been renamed to `BoxAnnotator`. `BoundingBoxAnnotator` will be removed in supervision-0.26.0.\n"
     ]
    }
   ],
   "source": [
    "# import threading\n",
    "from inference import InferencePipeline\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "# import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SupervisionWarnings: BoundingBoxAnnotator is deprecated: `BoundingBoxAnnotator` is deprecated and has been renamed to `BoxAnnotator`. `BoundingBoxAnnotator` will be removed in supervision-0.26.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating inference sessions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded in 2.62 seconds\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator()\n",
    "LABEL_ANNOTATOR = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
    "\n",
    "# tracker = sv.ByteTrack()\n",
    "\n",
    "# detection_polygon =np.array([[64, 1063],[3680, 1707],[3716, 2099],[84, 2075]]) # clear highway\n",
    "# detection_zone = sv.PolygonZone(polygon=detection_polygon, triggering_anchors=(sv.Position.BOTTOM_RIGHT, sv.Position.BOTTOM_LEFT)) # highway\n",
    "# unique_cars = set()\n",
    "\n",
    "# filter_polygon = np.array([[44, 987],[3740, 1647],[3752, 2135],[32, 2119]]) # clear highway \n",
    "# filter_zone = sv.PolygonZone(polygon=filter_polygon, triggering_anchors=(sv.Position.BOTTOM_RIGHT, sv.Position.BOTTOM_LEFT))\n",
    "\n",
    "# def get_crops(detections, image):\n",
    "\n",
    "    # result = {}\n",
    "    # for bbox, class_name in zip(detections.xyxy, detections.data[\"class_name\"]):\n",
    "    #     # print(\"class name in get crops: \", class_name)\n",
    "    #     x1, y1, x2, y2 = bbox\n",
    "    #     crop = image[int(y1):int(y2), int(x1):int(x2)]\n",
    "    #     crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #     if class_name in result:\n",
    "    #         result[class_name].append(crop)\n",
    "    #     else:\n",
    "    #         result[class_name] = [crop]\n",
    "\n",
    "    # return result\n",
    "\n",
    "# def background_task(results, frame):\n",
    "#     print(\"Background task\")\n",
    "#     detections = sv.Detections.from_inference(results)\n",
    "#     # print(\"background detections\", detections)\n",
    "#     car_features = detections[filter_zone.trigger(detections)]\n",
    "#     crops = get_crops(car_features, frame.image)\n",
    "#     # print(\"crops: \", crops)\n",
    "#     # his model has two classes. license-plate and vehicle\n",
    "#     # plate_img = Image.fromarray(crops[\"license plate\"][0])\n",
    "#     # vehicle_img = Image.fromarray(crops[\"vehicle\"][0])\n",
    "#     vehicle_img = Image.fromarray(crops[\"vehicle\"][0])\n",
    "\n",
    "#     # total_width = plate_img.width + vehicle_img.width\n",
    "#     total_width = vehicle_img.width\n",
    "#     # max_height = max(plate_img.height, vehicle_img.height)\n",
    "#     max_height = vehicle_img.height\n",
    "\n",
    "#     combined_img = Image.new('RGB', (total_width, max_height))\n",
    "#     # combined_img.paste(plate_img, (0, 0))\n",
    "#     # combined_img.paste(vehicle_img, (plate_img.width, 0))\n",
    "#     combined_img.paste(vehicle_img)\n",
    "#     combined_img.show()\n",
    "\n",
    "#     # save the image with different names for each car\n",
    "#     unique_filename = f\"./cropped_images/vehicle_{uuid.uuid1()}.png\"\n",
    "#     try:\n",
    "#         combined_img.save(unique_filename)\n",
    "#         print(\"Image saved\")\n",
    "#     except Exception as e:\n",
    "#         print(\"Error saving image: \", e)\n",
    "def call_back(results, frame):\n",
    "    \"\"\"\n",
    "    This function is called for each frame of the video.\n",
    "    \"\"\"\n",
    "    # detections = sv.Detections.from_inference(results).with_nms(threshold=0.0)\n",
    "    detections = sv.Detections.from_inference(results)\n",
    "    annotated_frame = BOUNDING_BOX_ANNOTATOR.annotate(scene=frame.image.copy(), detections=detections)\n",
    "    annotated_frame = LABEL_ANNOTATOR.annotate(scene=annotated_frame, detections=detections)\n",
    "\n",
    "    cv2.namedWindow(\"Vehicle Analytics\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Vehicle Analytics\", 1600, 900)\n",
    "    cv2.imshow(\"Vehicle Analytics\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        pipeline.terminate()\n",
    "\n",
    "    # tracked_detections = tracker.update_with_detections(detections)\n",
    "    # # print(\"Tracked detections\", tracked_detections)\n",
    "    # # print(f\"Tracked detections:\\nclass_id: {0}, class_name: {1}\",tracked_detections.class_id, tracked_detections.data[\"class_name\"])\n",
    "    # detected_cars = tracked_detections[tracked_detections.class_id == 0] # also change this according to class index\n",
    "    # # print(\"Detected cars\", detected_cars)\n",
    "    # # print(f\"Detected cars:\\nclass_id: {0}, class_name: {1}\", detected_cars.class_id, detected_cars.data[\"class_name\"])\n",
    "    # cars_in_zone = detected_cars[detection_zone.trigger(detected_cars)]\n",
    "    # # print(\"Cars in zone\", cars_in_zone)\n",
    "\n",
    "    # global unique_cars\n",
    "\n",
    "    # for car in cars_in_zone.tracker_id:\n",
    "    #     print(\"Car ID: \", car)\n",
    "    #     if not car in unique_cars:\n",
    "    #         unique_cars.add(car)\n",
    "    #         background_thread = threading.Thread(target=background_task, args=(results, frame))\n",
    "    #         background_thread.start()\n",
    "\n",
    "pipeline = InferencePipeline.init_with_yolo_world(\n",
    "    video_reference=r\"..\\videos\\highway_2.mp4\",\n",
    "    classes=[\"vehicle\"],\n",
    "    model_size=\"s\",\n",
    "    confidence=0.05,\n",
    "    on_prediction=call_back,\n",
    ")\n",
    "# start the pipeline\n",
    "pipeline.start()\n",
    "# wait for the pipeline to finish\n",
    "pipeline.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".major_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
